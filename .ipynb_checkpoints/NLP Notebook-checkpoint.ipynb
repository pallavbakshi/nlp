{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLP Notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re #regex\n",
    "import pysrt #subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position of abc in abcdef:  (0, 3)\n",
      "word match:  (0, 1)\n",
      "greedy word match:  (0, 5)\n",
      "digit match:  (0, 1)\n",
      "greedy digit match:  (0, 5)\n",
      "space match:  (0, 1)\n",
      "greedy space match:  (0, 3)\n",
      "wildcard match:  (0, 18)\n",
      "no space match:  (0, 10)\n",
      "lowercase match:  (0, 3)\n"
     ]
    }
   ],
   "source": [
    "# regex || re basics\n",
    "\n",
    "# matching a pattern with string\n",
    "pattern = 'abc'\n",
    "string1 = 'abcdef'\n",
    "pattern_match_string1 = re.match(pattern, string1)\n",
    "print \"position of {} in {}: \".format(pattern, string1), pattern_match_string1.span()\n",
    "\n",
    "# word match\n",
    "word_match = re.match('\\w', 'hello, how are you?')\n",
    "print \"word match: \", word_match.span()\n",
    "\n",
    "# greedy word match\n",
    "word_match = re.match('\\w+', 'hello, how are you?')\n",
    "print \"greedy word match: \", word_match.span()\n",
    "\n",
    "\n",
    "# digit match\n",
    "digit_match = re.match('\\d', '4j454')\n",
    "print \"digit match: \", digit_match.span()\n",
    "\n",
    "\n",
    "# greedy digit match\n",
    "digit_match = re.match('\\d+', '54353j34')\n",
    "print \"greedy digit match: \", digit_match.span()\n",
    "\n",
    "\n",
    "# space match\n",
    "space_match = re.match('\\s', ' hello')\n",
    "print \"space match: \", space_match.span()\n",
    "\n",
    "\n",
    "# greedy space match\n",
    "space_match = re.match('\\s*', '   34344')\n",
    "print \"greedy space match: \", space_match.span()\n",
    "\n",
    "\n",
    "# wildcard\n",
    "wildcard_match = re.match('.*', 'anything anything9')\n",
    "print \"wildcard match: \", wildcard_match.span()\n",
    "\n",
    "\n",
    "# greedy no space match\n",
    "no_space_match = re.match('\\S*', '99943221dd 33')\n",
    "print \"no space match: \", no_space_match.span()\n",
    "\n",
    "\n",
    "# lowercase match\n",
    "lowercase_match = re.match('[a-z]+', 'afd, how are you')\n",
    "print \"lowercase match: \", lowercase_match.span()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split on space:  ['Split', 'on', 'spaces']\n",
      "split on w:  ['hello, ho', ' are you doing?']\n",
      "words:  ['What', 'are', 'you', 'doing', 'You', 'can', 't', 'do', 'this']\n"
     ]
    }
   ],
   "source": [
    "# re module main functions\n",
    "# 1. match\n",
    "# 2. search\n",
    "# 3. findall\n",
    "# 4. split\n",
    "\n",
    "# split on space\n",
    "split_array = re.split('\\s+', 'Split on spaces')\n",
    "print \"split on space: \", split_array\n",
    "\n",
    "\n",
    "# split on letter w\n",
    "split_array_w = re.split('w', 'hello, how are you doing?')\n",
    "print \"split on w: \", split_array_w\n",
    "\n",
    "\n",
    "# findall words\n",
    "words = re.findall('\\w+', \"What are you doing. You can't do this.\")\n",
    "print \"words: \", words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object at 0x7fd606518920>\n",
      "None\n",
      "<_sre.SRE_Match object at 0x7fd606518920>\n",
      "<_sre.SRE_Match object at 0x7fd606518920>\n"
     ]
    }
   ],
   "source": [
    "# match vs search\n",
    "\n",
    "# match will try to match the string from the beginning until it can no longer match it\n",
    "print (re.match('abcd', 'abcdefgh'))\n",
    "\n",
    "print (re.match('abcd', 'xabcd')) # None returned\n",
    "\n",
    "# search will try go through the entire string to look for search options\n",
    "print (re.search('abcd', 'abcdefgh'))\n",
    "\n",
    "print (re.search('abcd', 'xabcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an amazing way to practice regex', \" Don't you think so\", ' Tell me', '']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is an amazing way to practice regex. Don't you think so? Tell me!\"\n",
    "\n",
    "# Breaking the sentence on sentence ending\n",
    "sentence_endings = r\"[.!?]\"\n",
    "print(re.split(sentence_endings,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'Don', 'Tell']\n"
     ]
    }
   ],
   "source": [
    "# Find all the words starting with capital letter\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'amazing', 'way', 'to', 'practice', 'regex.', \"Don't\", 'you', 'think', 'so?', 'Tell', 'me!']\n"
     ]
    }
   ],
   "source": [
    "# Break the sentence on space\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['2', '3']\n"
     ]
    }
   ],
   "source": [
    "# Find digits in the sentence (if any)\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, sentence)) # no digits present in the sentence\n",
    "\n",
    "sentence2 = \"This is another amazing sentence. Let's call it sentence 2. No? Okay! Let's call it sentence 3.\"\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'amazing', 'way', 'to', 'practice', 'regex', \"Don't\", 'you', 'think', 'so', 'Tell', 'me']\n"
     ]
    }
   ],
   "source": [
    "# Break the sentence on space and remove sentence endings\n",
    "print([re.split(sentence_endings, x)[0] for x in re.split(spaces, sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2546\n",
      "sen 0:  (BIRDS CHIRPING)\n",
      "sen 1:  (TELEPHONE RINGING)\n",
      "sen 2:  MAN: Hiya, Frank.\n",
      "How are the wife and kids?\n",
      "sen 3:  You know, for you,\n",
      "I'm considering treasury bonds\n",
      "sen 4:  and utility stocks. Smoke?\n",
      "sen 5:  JARED: <i>In the late '70s,\n",
      "banking wasn't a job</i>\n",
      "{\n",
      "    \"ANTHONY\": 1, \n",
      "    \"BEN\": 11, \n",
      "    \"BRIAN WILLIAMS\": 1, \n",
      "    \"CASEY\": 2, \n",
      "    \"CHARLIE\": 15, \n",
      "    \"CHRIS\": 3, \n",
      "    \"COMMENTATOR\": 1, \n",
      "    \"CYNTHIA\": 1, \n",
      "    \"DANNY\": 19, \n",
      "    \"DAVID\": 3, \n",
      "    \"DEEB\": 4, \n",
      "    \"DOUG\": 1, \n",
      "    \"FEMALE REPORTER\": 1, \n",
      "    \"GEORGIA\": 2, \n",
      "    \"GUARD\": 1, \n",
      "    \"JAMIE\": 17, \n",
      "    \"JARED\": 32, \n",
      "    \"JASON WAHLER\": 1, \n",
      "    \"KATHY\": 1, \n",
      "    \"KEN\": 1, \n",
      "    \"LAUREN CONRAD\": 1, \n",
      "    \"LAWRENCE\": 2, \n",
      "    \"LEWIS\": 2, \n",
      "    \"LUCY\": 7, \n",
      "    \"MALE AUTOMATED VOICE\": 1, \n",
      "    \"MALE REPORTER\": 1, \n",
      "    \"MAN\": 18, \n",
      "    \"MAN IN BLACK\": 1, \n",
      "    \"MARK\": 38, \n",
      "    \"MARLENE\": 3, \n",
      "    \"MARTIN\": 1, \n",
      "    \"MIKE\": 12, \n",
      "    \"MIKE'S DAD\": 1, \n",
      "    \"MIKE'S MOM\": 1, \n",
      "    \"MIKE'S WIFE\": 1, \n",
      "    \"MR. CHAU\": 1, \n",
      "    \"PORTER\": 19, \n",
      "    \"REPORTER\": 2, \n",
      "    \"RICHARD\": 1, \n",
      "    \"THERAPIST\": 1, \n",
      "    \"VINNIE\": 24, \n",
      "    \"WOMAN\": 7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "# Different types of tokenization: word_tokenize, sent_tokenize, regexp_tokenize, TweetTokenizer\n",
    "\n",
    "from collections import Counter\n",
    "from prettyprint import pp\n",
    "\n",
    "# working with the big short film dataset\n",
    "raw_movie = pysrt.open('dataset/the_big_short_script.srt')\n",
    "\n",
    "# print raw_movie[0]\n",
    "print (len(raw_movie))\n",
    "\n",
    "# dialogue_speaker\n",
    "dialogue_speaker = []\n",
    "\n",
    "i = 0\n",
    "for sentence in raw_movie:\n",
    "    print \"sen {}: \".format(i), sentence.text\n",
    "    i = i+1\n",
    "    if (i > 5):\n",
    "        break\n",
    "        \n",
    "# find all the different people that had dialogue\n",
    "for sentence in raw_movie:\n",
    "    [dialogue_speaker.append(j[:-1]) if j else None for j in re.findall(r'[A-Z]+.*:', sentence.text)]\n",
    "\n",
    "dialogue_speaker = Counter(dialogue_speaker)\n",
    "\n",
    "pp(dialogue_speaker)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2931\n",
      "[u'(', u'BIRDS', u'CHIRPING', u')', u'(']\n",
      "[u'raining', u'reform.', u'felt', u'chaos', u'four']\n"
     ]
    }
   ],
   "source": [
    "# breaking the text into sentences\n",
    "\n",
    "i = 0\n",
    "\n",
    "word_tokens = []\n",
    "for sentence in raw_movie:\n",
    "    sent_tokens = nltk.tokenize.sent_tokenize(sentence.text)\n",
    "    for word in sent_tokens:\n",
    "        [word_tokens.append(j) for j in nltk.tokenize.word_tokenize(word)]\n",
    "    i = i + 1\n",
    "#     if (i > 5):\n",
    "#         break\n",
    "        \n",
    "unique_tokens = list(set(word_tokens))\n",
    "\n",
    "print len(unique_tokens)\n",
    "\n",
    "print word_tokens[:5]\n",
    "\n",
    "print unique_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pattern_match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d00cc65c7fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mpattern_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pattern_match' is not defined"
     ]
    }
   ],
   "source": [
    "print pattern_match.group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
